
# Migration de donnÃ©es CSV vers MongoDB (Docker/AWS-ready)

Ce dÃ©pÃ´t contient un script Python qui migre un dataset de santÃ© (CSV) vers MongoDB.
Il applique des **transformations contrÃ´lÃ©es**, crÃ©e un **index composÃ© unique** pour assurer l'**idempotence**,
et propose un mode **upsert** pour rÃ©exÃ©cuter la migration sans doublons.

---

## ğŸ¯ Objectif
- Charger un CSV volumineux dans MongoDB de maniÃ¨re **reproductible**.
- **Nettoyer/normaliser** certaines colonnes et **typer** les champs.
- EmpÃªcher les doublons grÃ¢ce Ã  une **clÃ© naturelle** + **index unique**.
- Permettre des **rÃ©exÃ©cutions sÃ»res** via **upsert**.

---

## ğŸ§± SchÃ©ma logique (document MongoDB)

| Champ (Mongo)        | Source CSV              | Type cible        | RÃ¨gle de transformation |
|----------------------|-------------------------|-------------------|-------------------------|
| `name`               | `Name`                  | string            | `lower()`              |
| `age`                | `Age`                   | int               | coercition â†’ int       |
| `gender`             | `Gender`                | string            | `lower()`              |
| `blood_type`         | `Blood Type`            | string            | `lower()`              |
| `medical_condition`  | `Medical Condition`     | string            | trim                   |
| `date_of_admission`  | `Date of Admission`     | datetime (00:00)  | parse `dayfirst=True` + normalisation date-only |
| `doctor`             | `Doctor`                | string            | trim                   |
| `hospital`           | `Hospital`              | string            | `lower()`              |
| `insurance_provider` | `Insurance Provider`    | string            | trim                   |
| `billing_amount`     | `Billing Amount`        | float             | coercition â†’ float     |
| `room_number`        | `Room Number`           | string            | conserver tel quel     |
| `admission_type`     | `Admission Type`        | string            | trim                   |
| `discharge_date`     | `Discharge Date`        | datetime (00:00)  | parse + normalisation  |
| `medication`         | `Medication`            | string            | trim                   |
| `test_results`       | `Test Results`          | string            | trim                   |
| `ingested_at`        | â€”                       | datetime (UTC)    | dÃ©fini Ã  lâ€™insertion   |
| `last_modified_at`   | â€”                       | datetime (UTC)    | dÃ©fini Ã  chaque upsert |
| `source`             | â€”                       | string            | `csv_migration_v2`     |

> Les colonnes CSV attendues (sensible Ã  la casse) :  
> `['Name','Age','Gender','Blood Type','Medical Condition','Date of Admission','Doctor','Hospital','Insurance Provider','Billing Amount','Room Number','Admission Type','Discharge Date','Medication','Test Results']`

---

## ğŸ”‘ ClÃ© naturelle & index

- **ClÃ© naturelle** choisie : (`name`, `gender`, `blood_type`, `date_of_admission`, `hospital`)
- Tous les champs de la clÃ© sont **normalisÃ©s** (lowercase) et la date est **au jour** (00:00:00)
- **Index composÃ© unique** pour empÃªcher les doublons :
  ```python
  collection.create_index(
      [("name", 1), ("gender", 1), ("blood_type", 1), ("date_of_admission", 1), ("hospital", 1)],
      unique=True,
      name="uniq_admission",
  )
  ```

**Pourquoi un index ?**  
Un index accÃ©lÃ¨re les recherches (Ã©vite le scan complet) et ici **garantit lâ€™unicitÃ©** des admissions.
Sans index unique, une rÃ©exÃ©cution du script pourrait insÃ©rer des doublons.

---

## âš™ï¸ Fonctionnement du script

Script principal : `migrate_to_mongo_upsert.py`

- Lecture streaming du CSV en **chunks** (`--chunksize`), transformation ligne par ligne.
- **Dry-run** pour prÃ©visualiser les documents transformÃ©s sans Ã©crire en base.
- **Upsert** par dÃ©faut : rÃ©exÃ©cutions idempotentes (mise Ã  jour si dÃ©jÃ  prÃ©sent, insertion sinon).
- **Index** : `--create-indexes` crÃ©e lâ€™index unique une fois.
- **Journaux** : niveau contrÃ´lable via `--log-level` (INFO par dÃ©faut).

---

## ğŸ“¦ PrÃ©requis & installation

- Python 3.10+ (fonctionne trÃ¨s bien dans un environnement conda)
- MongoDB accessible (local ou distant)
- Installer les dÃ©pendances :
  ```bash
  pip install -r requirements.txt
  ```

> Variante conda :  
> `conda install pandas pymongo` puis `pip install python-dotenv` si besoin.

---

## â–¶ï¸ Exemples dâ€™exÃ©cution

### 1) PrÃ©visualisation (dry-run)
```bash
python migrate_to_mongo_upsert.py --csv /chemin/healthcare_dataset.csv --dry-run
```

### 2) CrÃ©ation de lâ€™index (une fois) + upsert
```bash
python migrate_to_mongo_upsert.py   --csv /chemin/healthcare_dataset.csv   --mongo-uri "mongodb://localhost:27017"   --db healthcare --collection patients   --create-indexes --upsert
```

### 3) RÃ©exÃ©cuter en toute sÃ©curitÃ© (idempotent)
```bash
python migrate_to_mongo_upsert.py --csv /chemin/healthcare_dataset.csv --upsert
```

### 4) InsÃ©rer sans upsert (non recommandÃ© ici)
```bash
python migrate_to_mongo_upsert.py --csv /chemin/healthcare_dataset.csv --no-upsert
```

---

## ğŸ” Variables dâ€™environnement (.env pris en charge)
Le script charge `.env` si prÃ©sent (via `python-dotenv`) :
```
CSV_PATH=/chemin/healthcare_dataset.csv
MONGO_URI=mongodb://localhost:27017
MONGO_DB=healthcare
MONGO_COLLECTION=patients
LOG_LEVEL=INFO
```
> Chaque option peut aussi Ãªtre passÃ©e via la ligne de commande.

---

## ğŸ§ª Tests & qualitÃ©
- Ajoutez des tests unitaires pour `transform_row` (types, normalisation) et un test dâ€™intÃ©gration simple avec une base Ã©phÃ©mÃ¨re (Mongo en container).
- DÃ©tectez les lignes incomplÃ¨tes : le script les **ignore** en les **loggant**.

---

## ğŸ³ Et avec Docker ? (aperÃ§u)
Un `requirements.txt` permet dâ€™installer les dÃ©pendances **dans lâ€™image** :
```dockerfile
FROM python:3.11-slim
WORKDIR /app
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt
COPY migrate_to_mongo_upsert.py .
CMD ["python", "migrate_to_mongo_upsert.py", "--csv", "/data/healthcare_dataset.csv", "--create-indexes", "--upsert"]
```
Vous monterez votre CSV dans `/data` via `-v` ou `Docker Compose`.

---

## â—Points dâ€™attention
- **ClÃ© naturelle** : si la logique Ã©volue (ex. ajouter `room_number`), mettre Ã  jour **lâ€™index** et **le filtre dâ€™upsert**.
- **Fuseaux horaires** : les dates sont stockÃ©es en naÃ¯f (00:00). Si besoin de TZ-aware, on adaptera.
- **Concurrence** : en cas dâ€™Ã©critures concurrentes multiples, ajouter des retries sur codes dâ€™erreur spÃ©cifiques.
- **DonnÃ©es manquantes** : les lignes sans clÃ© naturelle complÃ¨te sont ignorÃ©es (voir logs).

---

## ğŸ“š Commandes utiles MongoDB
```javascript
// VÃ©rifier l'index
db.patients.getIndexes()

// Compter les documents
db.patients.countDocuments({})

// Rechercher par date d'admission
db.patients.find({ date_of_admission: ISODate("2019-08-20T00:00:00Z") }).limit(5)
```

---

## Licence
Usage pÃ©dagogique.
